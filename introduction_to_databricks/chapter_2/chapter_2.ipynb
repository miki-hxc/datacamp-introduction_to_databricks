{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8397c63",
   "metadata": {},
   "source": [
    "# Exploring catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8f7e7",
   "metadata": {},
   "source": [
    "Sierra Publishing hired you to work as a data engineer in their centralized IT department. You receive various daily requests from different parts of your organization regarding different datasets. Historically, you have explored data programmatically by reading different datasets one at a time.\n",
    "\n",
    "<img src='img/Data Explorer.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348eb5b",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "What is one of the primary benefits of using the Catalog Explorer instead of your previous approach?\n",
    "\n",
    "- Provides the code to query a specific table. ❌\n",
    "- Ability to see sample data for a particular table. ✅\n",
    "- See the lineage for your data assets. ❌\n",
    "- Ability to automatically clean your data. ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c5d93",
   "metadata": {},
   "source": [
    "# Adding your datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf94cd",
   "metadata": {},
   "source": [
    "In this exercise, you will integrate a new dataset into Databricks using csv file.\n",
    "\n",
    "The data governance officer for Sierra Publishing has the important job of organizing and maintaining different datasets for the organization. In this scenario, you have requested that the data governance officer review some historical publication data that will help you with one of your projects. Help your colleague integrate and organize the new dataset into your Unity Catalog implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d33c9",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Navigate to the Data Ingestion section using the menu on the left-hand side of the UI. In the Data Ingestion window, click on Create or modify table.\n",
    "\n",
    "2. Click browse in order to open a new pop-up window. Navigate to the Desktop folder, then click on Datasets. Select the CSV file called bx_books_file.csv and then click Open.\n",
    "\n",
    "3. After uploading, you will see a preview of your data, as well as options to select your catalog and schema of choice. Make sure that the following settings are selected at the top of the page.\n",
    "    - Catalog: Starts with databricks_ws_xxxx\n",
    "    - Schema: default\n",
    "\n",
    "    After checking the settings are as above, click Create table in the bottom right of the window.\n",
    "\n",
    "4. If not redirected automatically, navigate to the Catalog button on the left-hand side of the Databricks UI and find the catalog and schema you used. Click on the new table name bx_bookx_file and review the Overview details of the table.\n",
    "\n",
    "5. Looking at the overview data for the `bx-books_file` dataset, what is the data type for the \"Year-Of-Publication\" column?\n",
    "\n",
    "    - string ❌\n",
    "    - date ❌\n",
    "    - bigint ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25ceb2",
   "metadata": {},
   "source": [
    "# Setting Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20841e",
   "metadata": {},
   "source": [
    "In this exercise, you will update the permission settings of your new data table.\n",
    "\n",
    "You are not done working with the data governance officer! Now that you have uploaded the data to a catalog and schema, you will support the data governance officer to ensure that proper access and governance to the data is provided.\n",
    "\n",
    "As a reminder, you uploaded the bx_books_file.csv data into the following catalog and schema:\n",
    "\n",
    "- Catalog: Starts with databricks_ws_xxxx (will be similar to the username used to log in)\n",
    "- Schema: default\n",
    "\n",
    "*We do not recommend doing so, but if you lost progress you will have to create the data table bx_books_file again using the information in the Adding your datasets exercise.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be92df8",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Navigate to your Catalog Explorer. Locate the catalog and schema where you wrote your dataset, and click on the schema.\n",
    "\n",
    "2. You should see a Permissions for the default schema after clicking on it. Click on this to see who has access to the schema currently.\n",
    "\n",
    "3. Now click into the table you created, and check the permissions for bx_books_file. Notice how similar or dissimilar these are to the schema-level permissions.\n",
    "\n",
    "4. In the Permissions tab of bx_books_file, click the Grant button to provide access to your data consumers. In the Principals search, type \"users\" and select the group All account users to provided all privileges to\n",
    "\n",
    "5. Which of the following statements best describes the relationship between schema-level and table-level permissions in Unity Catalog?\n",
    "    - Permissions you set at the schema are forced down to the thable. You cannot change permissions at the table level. ❌\n",
    "    - Permissions from the schema will trickle down to the table, but you can also change them at the table level. ✅\n",
    "    - Permissions are set separately at the schema and the table levels. There is no relationship. ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389868c",
   "metadata": {},
   "source": [
    "# Node capabilities: Single vs. Multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13ed7a",
   "metadata": {},
   "source": [
    "As one of the Databricks Workspace Administrators at Sierra Publishing, one of your tasks is to review requests for new clusters and create them for different user groups. You would like your user base to become more self sufficient and create their own clusters, so you want to create some guidelines to help your users create the right kind of cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecbbd3",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "For each of the following scenarios, select whether a single-node or multi-node cluster would be better and the most efficient option. Each scenario will only fit into one bucket.\n",
    "\n",
    "- **Single-node:** Exploratory Data Analysis with pandas and seaborn, Transforming a dataset that is 30 GB in size.\n",
    "- **Multi-node:** Using SparkML to train a complex AI model, Transforming a dataset that is 30 TB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572f5fa",
   "metadata": {},
   "source": [
    "# Configuring clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afcc1a",
   "metadata": {},
   "source": [
    "You have received various requests from your central IT group to rein in the kinds of clusters that can be created in Databricks.\n",
    "\n",
    "The IT team will start implementing different cluster policies for the different groups using the Databricks platform. Since you lead your data engineering team, the IT team would like you to provide a list of configurations you need to complete your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b5254",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "Which of the following is not a valid cluster configuration in Databricks?\n",
    "\n",
    "- Cluster monthly budget ✅\n",
    "- Databricks Runtime ❌\n",
    "- Auto-termination time ❌\n",
    "- Node instance types ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b402c",
   "metadata": {},
   "source": [
    "# Create your first cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42bbf1",
   "metadata": {},
   "source": [
    "In this exercise, you will create your first cluster.\n",
    "\n",
    "You have continued investigating the Databricks UI and how it is being implemented at Sierra Publishing. The CTO wants you to keep going and suggests that now would be an excellent opportunity to create your own clusters, something you will need to do regularly when working with Databricks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c838b44",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Navigate to the Compute section of the platform.\n",
    "\n",
    "2. Here you will see all compute resources that you have access to. In the top right of this window, click the Create with Personal Compute button.\n",
    "\n",
    "3. Name the new cluster \"first_cluster\". This cluster will be used in another section to run some quick commands.\n",
    "\n",
    "4. Create the cluster with the following configurations:\n",
    "    - Databricks runtime: 14.3 LTS (not the GPU one)\n",
    "    - Node type: Standard_F4s\n",
    "    - Terminate after: 10 minutes\n",
    "\n",
    "5. Create the cluster using the appropriate button at the bottom of your screen.\n",
    "\n",
    "6. How many DBUs per hour will this cluster cost? `0.5`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
